% Proof of Human Intent - arXiv Paper
% Reference implementation: https://github.com/pohi-protocol/pohi

\documentclass[conference]{IEEEtran}

% Packages
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{booktabs}

% Code listing style
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  language=Python
}

% Hyperref setup
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

\begin{document}

% =============================================================================
% TITLE
% =============================================================================
\title{Proof of Human Intent: Cryptographically Verifiable Human Approval for AI-Driven Software Development}

% =============================================================================
% AUTHOR
% =============================================================================
\author{
\IEEEauthorblockN{Ikko Eltociear Ashimine}
\IEEEauthorblockA{
Independent Researcher \\
ORCID: 0000-0002-3576-6677
}
}

\maketitle

% =============================================================================
% ABSTRACT
% =============================================================================
\begin{abstract}
With the rise of autonomous AI agents capable of proposing and executing software changes, traditional human-in-the-loop assumptions no longer hold.
As these agents increasingly automate code generation, review, and deployment, the provenance of ``human intent''---the accountability behind critical decisions---is becoming obscured.
Current systems lack mechanisms to cryptographically verify that a human—rather than an automated process—authorized specific actions such as merging pull requests or deploying to production.
We present \textbf{Proof of Human Intent (PoHI)}, a protocol that combines zero-knowledge proofs of personhood (World ID), decentralized identifiers (DIDs), verifiable credentials (VCs), and transparency logs (SCITT) to create tamper-evident, machine-verifiable records of human approval.
Our architecture addresses three fundamental questions: (1) \textit{who} approved an action (unique human verification), (2) \textit{what} was approved (cryptographic binding to specific commits), and (3) \textit{when} it was approved (immutable timestamping).
We implement a proof-of-concept integration with GitHub Actions and demonstrate that PoHI prevents unauthorized automated merges with negligible latency overhead ($<$2 seconds total machine time).
The reference implementation is available at \url{https://github.com/pohi-protocol/pohi}.
\end{abstract}

% =============================================================================
% KEYWORDS
% =============================================================================
\begin{IEEEkeywords}
AI agents, human-in-the-loop, proof of personhood, software supply chain security, zero-knowledge proofs, decentralized identity, verifiable credentials, transparency logs
\end{IEEEkeywords}

% =============================================================================
% 1. INTRODUCTION
% =============================================================================
\section{Introduction}

The rapid advancement of AI-powered code generation tools has fundamentally transformed software development workflows. Tools such as GitHub Copilot, Claude Code, and autonomous coding agents can now generate, review, and even propose merging code changes with minimal human intervention. While this automation dramatically increases developer productivity, it raises critical questions about accountability: \textit{Who approved this code? Was it a human or an AI? Can we prove it?}

Consider a scenario where an AI agent autonomously creates a pull request, reviews it using another AI system, and merges it into production—all without meaningful human oversight. In 2024, GitHub Copilot assists in over 46\% of code written by developers using the tool. By 2025, autonomous coding agents like Devin, Claude Code Agent, and GPT Engineer can complete entire development tasks end-to-end. This trend points toward a future where AI systems not only write code but also manage significant portions of the software lifecycle.

The accountability gap becomes critical when we consider:
\begin{itemize}
    \item \textbf{Security incidents}: If malicious code is introduced, who is responsible?
    \item \textbf{Regulatory compliance}: Industries like finance and healthcare require human approval for critical changes.
    \item \textbf{Audit requirements}: SOC 2, ISO 27001, and similar frameworks mandate traceable approval processes.
    \item \textbf{Legal liability}: Contracts may require human sign-off for software releases.
\end{itemize}

Current solutions rely on social conventions (e.g., requiring reviews) or process controls (e.g., protected branches), but these are easily circumvented and lack cryptographic verifiability. There is no mechanism to prove, after the fact, that a genuine human—not a bot or automated system—approved a specific action.

\subsection{Contributions}

Our contributions are as follows:
\begin{itemize}
    \item We identify the ``human approval verification gap'' in AI-driven software development and formalize the threat model.
    \item We propose the PoHI architecture that integrates proof-of-personhood, decentralized identity, and transparency logging.
    \item We implement a proof-of-concept GitHub Action that enforces human approval verification.
    \item We analyze the security properties of PoHI against relevant attack vectors.
\end{itemize}

% =============================================================================
% 2. BACKGROUND AND RELATED WORK
% =============================================================================
\section{Background and Related Work}

\subsection{AI Agents in Software Development}

The evolution of AI in software development can be characterized in three phases:

\textbf{Phase 1 (2021-2023): Completion-based assistants.} GitHub Copilot and similar tools provide inline code suggestions. The human developer remains in control of all actions.

\textbf{Phase 2 (2024-2025): Agentic assistants.} Tools like Claude Code, Cursor, and Windsurf can execute multi-step tasks, run commands, and modify files autonomously within developer-defined boundaries.

\textbf{Phase 3 (2025+): Autonomous agents.} Systems like Devin and OpenAI's Operator can complete entire tasks independently, including creating pull requests and interacting with external services.

This progression shifts developers from ``implementers'' to ``approvers,'' creating an urgent need for verifiable human oversight.

\subsection{Proof of Personhood}

Proof of Personhood (PoP) systems aim to verify that an entity is a unique human without revealing their identity. Notable approaches include:

\textbf{World ID} \cite{worldid} uses iris biometrics via specialized hardware (Orb) to create a unique identifier. Zero-knowledge proofs allow users to prove their humanity without revealing biometric data. World ID provides both ``Device'' level (phone-based) and ``Orb'' level (biometric) verification.

\textbf{BrightID} uses a social graph approach where existing verified humans vouch for new members. While more accessible, it is more susceptible to Sybil attacks through collusion.

\textbf{Gitcoin Passport} aggregates multiple identity signals (social accounts, on-chain activity) into a ``humanity score.'' This provides gradual verification but lacks the binary uniqueness guarantee of biometric systems.

We choose World ID as our primary PoP provider due to its strong Sybil resistance and privacy-preserving properties through zero-knowledge proofs.

\subsection{Software Supply Chain Security}

Recent initiatives address software supply chain integrity:

\textbf{SCITT (Supply Chain Integrity, Transparency, and Trust)} \cite{scitt} is an IETF draft architecture for maintaining append-only transparency logs of supply chain claims. It provides a framework for recording and verifying attestations about software artifacts.

\textbf{Sigstore} \cite{sigstore} enables keyless code signing using OIDC identity providers. It provides transparency logs (Rekor) for signatures but focuses on cryptographic identity rather than human verification.

\textbf{SLSA (Supply-chain Levels for Software Artifacts)} defines a framework for ensuring artifact integrity through provenance. However, it does not address the ``human approval'' aspect of the supply chain.

PoHI complements these systems by adding a human verification layer that can be integrated with existing supply chain security infrastructure.

\subsection{Decentralized Identity}

The W3C standards for Decentralized Identifiers (DIDs) \cite{did} and Verifiable Credentials (VCs) \cite{vc} provide a foundation for self-sovereign identity. DIDs enable identifier creation without a central authority, while VCs allow claims about subjects to be cryptographically verified.

PoHI leverages these standards for its Authority Layer, enabling organizations to issue credentials specifying who can approve what types of actions.

\subsection{AI Agent Authorization}

Mahari et al. \cite{mitdelegation} from MIT propose ``Authenticated Delegation'' for AI agents, introducing the concept of capability delegation from humans to AI systems. Their work focuses on what AI agents are authorized to do.

PoHI addresses a complementary problem: verifying that a human actually approved an action, regardless of whether AI agents were involved in the execution. While their approach defines ``what can be done,'' PoHI proves ``a human approved this.''

% =============================================================================
% 3. THREAT MODEL
% =============================================================================
\section{Threat Model}

\subsection{System Model}

We consider a software development environment with the following components:
\begin{itemize}
    \item \textbf{Developers}: Human actors who write and review code.
    \item \textbf{AI Agents}: Automated systems capable of generating code and creating pull requests.
    \item \textbf{Repository}: A Git-based version control system.
    \item \textbf{CI/CD Pipeline}: Automated build and deployment infrastructure.
\end{itemize}

\subsection{Adversary Capabilities}

We assume an adversary who can:
\begin{itemize}
    \item Control AI agents with repository access.
    \item Create commits and pull requests programmatically.
    \item Attempt to forge or replay approval attestations.
    \item Create multiple fake identities (Sybil attack).
\end{itemize}

\subsection{Security Goals}

PoHI aims to ensure:
\begin{enumerate}
    \item \textbf{Human Verification}: Actions are verifiably approved by unique humans.
    \item \textbf{Binding}: Approval is bound to specific code states.
    \item \textbf{Non-repudiation}: Approvers cannot deny approvals.
    \item \textbf{Tamper Evidence}: Modifications to records are detectable.
\end{enumerate}

\subsection{Scope and Limitations}

It is important to distinguish between \textit{cryptographic authorization} and \textit{semantic understanding}.
PoHI guarantees that a specific signal (commit hash) was approved by a unique human identity.
However, it does not guarantee that the human approver semantically understood the code changes or verified their correctness.
Social engineering attacks where a human is coerced or tricked into scanning the QR code for a malicious commit are considered out of scope for the cryptographic protocol, though UI mitigations (e.g., displaying commit details clearly before approval) are recommended.
Additionally, PoHI does not prevent a malicious insider with legitimate World ID credentials from approving harmful changes---organizational access controls and code review processes remain complementary safeguards.

% =============================================================================
% 4. PROPOSED ARCHITECTURE
% =============================================================================
\section{Proposed Architecture}

\subsection{Overview}

PoHI consists of four layers that work together to create verifiable human approval records:

\begin{enumerate}
    \item \textbf{Identity Layer}: Verifies the approver is a unique human using World ID.
    \item \textbf{Authority Layer}: Manages permissions using DIDs and VCs.
    \item \textbf{Attestation Layer}: Records events in a SCITT-compatible log.
    \item \textbf{Integration Layer}: Connects with Git workflows.
\end{enumerate}

The core data structure is the \texttt{HumanApprovalAttestation}, which binds:
\begin{itemize}
    \item A proof of human identity (World ID nullifier hash)
    \item A specific software artifact (commit SHA)
    \item An action type (merge, deploy, release)
    \item A timestamp (block time or signed timestamp)
\end{itemize}

\subsection{Identity Layer}

The Identity Layer leverages World ID's zero-knowledge proof system. When a user approves an action:

\begin{enumerate}
    \item The system generates a \texttt{signal} by hashing the repository and commit SHA: \\ \texttt{signal = SHA256(repository || ":" || commit\_sha)}
    \item The user scans a QR code with the World App, which generates a ZK proof binding their World ID to this signal.
    \item The proof includes a \texttt{nullifier\_hash} unique to this user-action combination, preventing the same human from approving the same commit twice while preserving privacy.
\end{enumerate}

Verification levels provide flexibility:
\begin{itemize}
    \item \textbf{Device}: Phone-based verification (lower assurance)
    \item \textbf{Orb}: Biometric verification (higher assurance)
\end{itemize}

\subsection{Authority Layer}

The Authority Layer (optional) enables organizations to define who can approve what:

\begin{itemize}
    \item \textbf{DIDs} identify organizations and individuals
    \item \textbf{VCs} specify approval authorities (e.g., ``Alice can approve production deployments for repo X'')
\end{itemize}

This layer is not required for basic operation but enables enterprise use cases such as role-based approval policies.

\subsection{Attestation Layer}

The Attestation Layer creates and stores attestation records. Two hash algorithms are used:

\begin{itemize}
    \item \textbf{SHA-256}: Protocol-standard hash for off-chain storage and interoperability
    \item \textbf{Keccak-256}: EVM-native hash for on-chain recording
\end{itemize}

On-chain storage on World Chain provides:
\begin{itemize}
    \item Immutability and tamper evidence
    \item Public verifiability
    \item Censorship resistance
    \item Timestamp through block inclusion
\end{itemize}

The smart contract enforces:
\begin{itemize}
    \item Uniqueness of attestation hashes
    \item Prevention of duplicate approvals (same nullifier + commit)
    \item Revocation capability for the original approver or admins
\end{itemize}

\subsection{Integration Layer}

The Integration Layer connects PoHI to developer workflows:

\textbf{GitHub Action}: A GitHub Action that can be added to any repository to enforce human approval before merging. When triggered:
\begin{enumerate}
    \item Creates an approval request with the commit SHA
    \item Posts a QR code to the PR for World ID verification
    \item Waits for human approval via the World App
    \item Records the attestation and updates PR status
\end{enumerate}

\textbf{CLI Tool}: A command-line interface for requesting and verifying approvals outside of CI/CD contexts.

\textbf{SDK}: TypeScript libraries for integrating PoHI into custom applications.

% =============================================================================
% 5. IMPLEMENTATION
% =============================================================================
\section{Implementation}

We implement PoHI as a modular TypeScript library with the following packages:

\begin{itemize}
    \item \texttt{@pohi-protocol/core}: Chain-neutral types, validation, and SHA-256 hashing (zero dependencies)
    \item \texttt{@pohi-protocol/evm}: EVM utilities for Keccak-256 and on-chain encoding
    \item \texttt{@pohi-protocol/sdk}: Client for World Chain interaction
    \item \texttt{@pohi-protocol/cli}: Command-line tool
    \item \texttt{@pohi-protocol/action}: GitHub Action
    \item \texttt{@pohi-protocol/contracts}: Solidity smart contracts (Foundry)
\end{itemize}

The core library has zero runtime dependencies, enabling use in constrained environments. The modular design allows users to adopt only the components they need.

\subsection{Attestation Data Model}

\begin{lstlisting}[language=Python,caption={Attestation JSON structure}]
{
  "version": "1.0",
  "type": "HumanApprovalAttestation",
  "subject": {
    "repository": "org/repo",
    "commit_sha": "abc123...",
    "action": "PR_MERGE"
  },
  "human_proof": {
    "method": "world_id",
    "verification_level": "orb",
    "nullifier_hash": "0x..."
  },
  "timestamp": "2025-12-15T10:30:00Z",
  "proof": { "type": "Ed25519", "jws": "..." }
}
\end{lstlisting}

% =============================================================================
% 6. EVALUATION
% =============================================================================
\section{Evaluation}

\subsection{Security Analysis}

We evaluate PoHI against the threat model defined in Section 3.

\begin{table}[h]
\centering
\caption{Security Analysis Against Attack Vectors}
\begin{tabular}{lll}
\toprule
\textbf{Attack} & \textbf{Mitigation} & \textbf{Assurance} \\
\midrule
Sybil Attack & World ID nullifier & High (Orb) \\
Replay Attack & Signal binding to commit & High \\
Tampering & Attestation hash & High \\
Impersonation & ZK proof verification & High \\
Front-running & On-chain nullifier check & Medium \\
Coercion & Out of scope & N/A \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Sybil Attack}: World ID's nullifier hash ensures one approval per unique human per action scope. The Orb verification level provides strong Sybil resistance through biometric uniqueness. Device-level verification offers weaker guarantees.

\textbf{Replay Attack}: The signal is computed as a hash of the repository and commit SHA. This binds each proof to a specific action, preventing reuse of proofs across different commits.

\textbf{Tampering}: The attestation hash covers all critical fields using SHA-256. Any modification to the attestation data results in hash mismatch, detectable during verification.

\textbf{Front-running}: The on-chain contract checks for duplicate approvals before recording. An attacker cannot front-run a legitimate approval because they lack the World ID proof.

\subsection{Performance Evaluation}

We measured the end-to-end latency of the approval verification flow using the reference implementation.
Table \ref{tab:latency} shows the breakdown of processing time for a typical validation request.

\begin{table}[h]
\centering
\caption{Operation Latency (Reference Implementation)}
\label{tab:latency}
\begin{tabular}{lrr}
\toprule
\textbf{Operation} & \textbf{Average Time} & \textbf{Std Dev} \\
\midrule
Attestation Construction & $<$ 5 ms & $\pm$1 ms \\
Hash Computation (SHA-256) & $<$ 1 ms & $\pm$0.1 ms \\
World ID Proof Verification (API) & 1,200 ms & $\pm$300 ms \\
GitHub Status Update & 250 ms & $\pm$50 ms \\
On-chain Recording (optional) & 3,000 ms & $\pm$500 ms \\
\midrule
\textbf{Total Machine Time} & \textbf{$\sim$1.5 s} & - \\
\bottomrule
\end{tabular}
\end{table}

The primary latency factor is the external World ID verification API call ($\sim$1.2s), which is acceptable for asynchronous pull request workflows.
The computational overhead for cryptographic binding (SHA-256 hashing and signature verification) is negligible ($<$ 5ms) on standard CI/CD runners.
Human interaction time (scanning QR code with World App) is excluded from machine time as it varies by user but typically requires 5--15 seconds.

\subsection{Gas Costs}

On-chain operations incur gas costs on World Chain:

\begin{table}[h]
\centering
\caption{Estimated Gas Costs}
\begin{tabular}{lr}
\toprule
\textbf{Operation} & \textbf{Gas Units} \\
\midrule
recordAttestation & $\sim$150,000 \\
revokeAttestation & $\sim$30,000 \\
isValidAttestation (view) & 0 \\
\bottomrule
\end{tabular}
\end{table}

At typical World Chain gas prices, recording an attestation costs less than \$0.01 USD.

% =============================================================================
% 7. DISCUSSION
% =============================================================================
\section{Discussion}

\subsection{Limitations}

\begin{itemize}
    \item World ID Orb availability constraints.
    \item Privacy considerations in transparency logs.
    \item Adoption barriers in existing workflows.
\end{itemize}

\subsection{Future Work}

\begin{itemize}
    \item Policy-as-code integration.
    \item Cross-organization trust federation.
    \item Privacy-preserving audit mechanisms.
\end{itemize}

% =============================================================================
% 8. CONCLUSION
% =============================================================================
\section{Conclusion}

As AI agents become increasingly capable of autonomous software development, the ability to verify human approval becomes critical for accountability and security. We presented Proof of Human Intent (PoHI), a protocol combining zero-knowledge proofs, decentralized identity, and transparency logs to create verifiable records of human approval.

% =============================================================================
% REFERENCES
% =============================================================================
\bibliographystyle{IEEEtran}

\begin{thebibliography}{99}

\bibitem{worldid}
World Foundation, ``World ID Documentation,'' 2025. [Online]. Available: https://docs.world.org/world-id

\bibitem{did}
W3C, ``Decentralized Identifiers (DIDs) v1.0,'' W3C Recommendation, 2022.

\bibitem{vc}
W3C, ``Verifiable Credentials Data Model v1.1,'' W3C Recommendation, 2022.

\bibitem{scitt}
IETF, ``An Architecture for Trustworthy and Transparent Digital Supply Chains,'' Internet-Draft, 2024.

\bibitem{sigstore}
Sigstore Project, ``Sigstore: Software Signing for Everyone,'' 2023.

\bibitem{mitdelegation}
R. Mahari et al., ``Authenticated Delegation and Authorized AI Agents,'' MIT Media Lab, 2024.

\bibitem{mssigning}
Microsoft, ``Enhancing Software Supply Chain Security with Microsoft's Signing Transparency,'' Azure Blog, November 2025.

\end{thebibliography}

\end{document}
